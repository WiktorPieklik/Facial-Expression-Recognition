{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.config import ROOT_DIR, IMG_SHAPE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   emotion                                             pixels     Usage\n0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>Usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n      <td>Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('fer2013.csv')\n",
    "ds.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ds['emotion'] = ds['emotion'].transform(lambda x: {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}[x])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# fig = px.histogram(ds, x='emotion', color='emotion', title='Histogram zbioru danych ze względu na emocje', labels={'emotion': 'Emocje'}, text_auto=True)\n",
    "# fig.update_layout(bargap=0.2, xaxis_title='Emocje', yaxis_title='Liczność')\n",
    "fig = px.histogram(x=['Angry', 'Fear', 'Neutral', 'Surprise', 'Happy', 'Sad', 'Disgust'], y=[8989,8989,8989,8989,8989,8989,8989,], title='Histogram zbioru danych po augmentacji')\n",
    "fig.update_layout(bargap=0.2, xaxis_title='Emocje', yaxis_title='Liczność')\n",
    "fig.write_image('augmented_ds.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/Users/wiktorpieklik/studies/2sem/sieci_neuronowe/projekt/src/notebooks/../../raw/images/Training\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 50\n",
    "\n",
    "TRAINNG_DIR = ROOT_DIR / \"../../raw/images\" / \"Training\"\n",
    "VAL_DIR = ROOT_DIR / \"../../raw/images\" / \"PublicTest\"\n",
    "print(TRAINNG_DIR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=TRAINNG_DIR,\n",
    "    label_mode='categorical',\n",
    "    batch_size=None,\n",
    "    color_mode='grayscale',\n",
    "    image_size=IMG_SHAPE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=VAL_DIR,\n",
    "    label_mode='categorical',\n",
    "    batch_size=None,\n",
    "    color_mode='grayscale',\n",
    "    image_size=IMG_SHAPE\n",
    ")\n",
    "rescale = tf.keras.layers.Rescaling(1. / 255)\n",
    "\n",
    "training_ds = training_ds.batch(BATCH_SIZE).map(lambda img, label: (rescale(img), label)).shuffle(30000).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).map(lambda img, label: (rescale(img), label)).prefetch(tf.data.AUTOTUNE)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "57683"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {0: 0, 1: 0, 2: 0}\n",
    "mapper = {\n",
    "    'Happy': 0,\n",
    "    'Neutral': 1,\n",
    "    'Sad': 2\n",
    "}\n",
    "labels = ['Happy', 'Neutral', 'Sad']\n",
    "path = ROOT_DIR / \"../../raw/images\" / \"Training\"\n",
    "total = len([obj for obj in path.rglob('*') if not obj.is_dir()])\n",
    "for i, label in enumerate(labels):\n",
    "    weights[i] = (1 / len(list((path / label).rglob(\"*\")))) * (total / 3.0)\n",
    "\n",
    "weights\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 48, 48, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 48, 48, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 24, 24, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 24, 24, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 24, 24, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 12, 12, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 12, 12, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 12, 12, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 12, 12, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 12, 12, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 12, 12, 256)       1638656   \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 12, 12, 512)       3277312   \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 12, 12, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 12, 12, 512)       6554112   \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 12, 12, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 12, 12, 512)       6554112   \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 12, 12, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,574,055\n",
      "Trainable params: 19,568,935\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(IMG_SHAPE + (1,)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(7,7), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(7,7), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAvgPool2D(),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "visualkeras.layered_view(model, legend=True, to_file='custom1.png')\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    return lr * np.exp(-.15)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath='best_model.h5'),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    PlotLossesKeras()\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=.01),\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    # class_weight=weights\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('best.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=ROOT_DIR / \"../../raw/images\" / \"PrivateTest\",\n",
    "    label_mode='categorical',\n",
    "    batch_size=None,\n",
    "    color_mode='grayscale',\n",
    "    image_size=IMG_SHAPE\n",
    ")\n",
    "\n",
    "test_ds = test_ds.batch(BATCH_SIZE).map(lambda img, label: (rescale(img), label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
